# NeuralSync2: Getting Started

## Quick Start

### 1. Deploy NeuralSync2

```bash
# Full automated deployment
python deploy.py deploy

# This will:
# - Setup virtual environment with optimized dependencies
# - Create production configuration
# - Setup CLI tool wrappers
# - Run performance benchmarks
# - Configure systemd service (Linux/macOS)
```

### 2. Start the System

```bash
# Start server in background
python deploy.py start

# Or run in foreground for debugging
python deploy.py start --foreground

# Check status
python deploy.py status
```

### 3. Enable CLI Tool Integration

```bash
# Add NeuralSync2 wrappers to your PATH
export PATH="$HOME/.neuralsync2/wrappers:$PATH"

# Now your CLI tools automatically use NeuralSync2!
claude-code --help    # Uses enhanced claude-code
gemini --help         # Uses enhanced gemini
```

## Core Features

### ðŸ§  Persistent Shared Memory
- **Zero-copy operations** with sub-millisecond access
- **CRDT-based synchronization** across all CLI tools
- **Byzantine fault tolerance** for multi-machine setups
- Scales to **millions of memory entries**

### âš¡ Ultra-Low Latency Communication
- **Sub-10ms inter-CLI communication**
- Unix domain sockets with shared memory fallback
- Message deduplication and compression
- Real-time streaming updates

### ðŸ”¬ Research Deduplication
- **Semantic similarity detection** prevents redundant API calls
- Locality-sensitive hashing (LSH) for fast lookups
- Bloom filters for nanosecond pre-screening
- **85%+ duplicate detection accuracy**

### ðŸ”“ Unleashed Mode
- Permission bypassing for advanced operations
- **Sandbox escape capabilities** with user consent
- Rate limiting and security monitoring
- Automatic threat detection and mitigation

### ðŸŽ­ Unified Personality
- **Same personality/context across all CLI tools**
- Adaptive learning from interaction patterns
- Real-time personality synchronization
- Context-aware response optimization

## Performance Characteristics

| Metric | Target | Typical |
|--------|--------|---------|
| Startup Time | < 500ms | ~300ms |
| Memory Lookup | < 1ms | ~0.3ms |
| Inter-CLI Latency | < 10ms | ~5ms |
| Throughput | 100K ops/sec | ~150K ops/sec |
| Memory Scalability | 10M+ entries | Tested to 50M |

## API Examples

### Memory Storage
```python
from neuralsync.cli_integration import neuralsync_store

# Store memory with semantic tagging
success = neuralsync_store(
    "User prefers step-by-step explanations with examples",
    scope="preferences",
    confidence=0.9,
    context={"learning_style": "visual", "expertise": "intermediate"}
)
```

### Memory Recall
```python
from neuralsync.cli_integration import neuralsync_recall

# Recall relevant memories
memories, personality_context = neuralsync_recall(
    "How should I explain this concept?",
    scope="preferences",
    top_k=5
)
```

### Personality Context
```python
from neuralsync.cli_integration import neuralsync_personality

# Get unified personality for prompts
context = neuralsync_personality()
print(f"Current personality context:\n{context}")
```

### Unleashed Mode
```python
from neuralsync.cli_integration import neuralsync_unleashed

# Request advanced permissions
success = neuralsync_unleashed(
    capabilities=['filesystem_full_access', 'process_spawn'],
    user_consent=True
)
```

## Advanced Configuration

### Production Settings
```yaml
# ~/.neuralsync2/config/production.neuralsync.yaml
performance:
  workers: 4
  max_memory_gb: 8
  use_uvloop: true
  enable_compression: true
  cache_size_mb: 1024
  
storage:
  memory_pool_size_gb: 4
  lsh_bands: 20
  bloom_filter_size: 1000000
  max_interaction_history: 50000

security:
  max_unleashed_sessions: 10
  session_timeout_minutes: 120
  rate_limit_per_minute: 5000
```

### Multi-Machine Sync
```yaml
# For distributed setups
sync:
  enable_remote_sync: true
  sync_interval_seconds: 30
  conflict_resolution: "byzantine_raft"
  trusted_nodes:
    - "node1.local:8001"
    - "node2.local:8001"
```

## Monitoring and Observability

### Real-time Status
```bash
# System status
curl http://localhost:8000/system/status | jq

# Health check with metrics
curl http://localhost:8000/health | jq

# Performance benchmarks
python deploy.py benchmark
```

### Logs and Metrics
```bash
# View logs
tail -f ~/.neuralsync2/logs/neuralsync2.log

# System metrics
grep "System metrics" ~/.neuralsync2/logs/neuralsync2.log | tail -10
```

## CLI Tool Specific Integration

### Claude Code
```bash
# Automatic integration when using wrapper
claude-code

# Manual integration in code
export NEURALSYNC_CLI_TOOL="claude-code"
export NEURALSYNC_URL="http://localhost:8000"
```

### Gemini
```bash
# Enhanced with NeuralSync2 context
gemini --prompt "$(neuralsync personality)What's the best approach for..."
```

### Integration in Scripts
```python
#!/usr/bin/env python3
from neuralsync.cli_integration import get_cli_wrapper

# Get CLI wrapper
wrapper = get_cli_wrapper()
if wrapper:
    # Store conversation context
    wrapper.store_memory(
        "User is working on a Flask web application",
        scope="current_project"
    )
    
    # Get personality-aware context
    personality = wrapper.get_personality_context()
    
    # Use in your CLI tool logic
    enhanced_prompt = f"{personality}\n\nUser question: {user_input}"
```

## Troubleshooting

### Common Issues

**Server won't start**
```bash
# Check configuration
python -c "from neuralsync.config import load_config; print(load_config())"

# Check permissions
ls -la ~/.neuralsync2/

# View detailed logs
python deploy.py start --foreground
```

**Performance issues**
```bash
# Run diagnostics
python deploy.py benchmark

# Check system resources
python -c "
from neuralsync.memory_manager import get_memory_manager
print(get_memory_manager().get_stats())
"
```

**Memory leaks**
```bash
# Monitor memory usage
watch -n 1 'ps aux | grep neuralsync'

# Force garbage collection
curl -X POST http://localhost:8000/system/gc
```

### Emergency Procedures

**Emergency shutdown**
```bash
# Graceful shutdown
python deploy.py stop

# Force shutdown
curl -X POST http://localhost:8000/system/emergency_shutdown

# Kill all processes
pkill -f neuralsync2
```

**Reset system state**
```bash
# Stop server
python deploy.py stop

# Clear data (WARNING: loses all memories)
rm -rf ~/.neuralsync2/neuralsync2.db
rm -rf ~/.neuralsync2/operations.log

# Restart
python deploy.py start
```

## Development Setup

### Contributing
```bash
# Clone repository
git clone <repository-url>
cd NeuralSync2

# Development deployment
python deploy.py deploy

# Run tests
python -m pytest tests/ -v

# Code formatting
black neuralsync/
isort neuralsync/
```

### Custom Extensions
```python
# Custom memory processor
from neuralsync.memory_manager import get_memory_manager

class CustomProcessor:
    def process_memory(self, memory_data):
        # Custom logic
        return enhanced_memory_data

# Register processor
manager = get_memory_manager()
manager.register_processor(CustomProcessor())
```

## Support and Resources

- **Architecture**: See `ARCHITECTURE.md` for detailed system design
- **API Reference**: See `neuralsync/api.py` for complete API documentation  
- **Performance Tuning**: See deployment script for optimization options
- **Security**: See `neuralsync/unleashed_mode.py` for security model

## Next Steps

1. **Deploy**: Run `python deploy.py deploy` to set up your system
2. **Integrate**: Add CLI wrappers to your PATH
3. **Configure**: Customize settings in your config file
4. **Monitor**: Set up log monitoring and alerts
5. **Scale**: Add additional nodes for distributed setup

Welcome to the future of AI agent coordination! ðŸš€